---
layout: post
title:  "URP杂记"
date:   2024-03-13 16:16:00 +0800
category: Unity
---

- [说明](#说明)
- [笔记](#笔记)
  - [ScriptableCullingParameters.conservativeEnclosingSphere](#scriptablecullingparametersconservativeenclosingsphere)
  - [RenderBufferLoadAction](#renderbufferloadaction)
  - [LUT(Look Up Table) for Color Grading in URP](#lutlook-up-table-for-color-grading-in-urp)
    - [总结](#总结)
    - [是否开启HDR渲染的差别](#是否开启hdr渲染的差别)
  - [Distance Attenuation and Spot Angle Attenuation in URP](#distance-attenuation-and-spot-angle-attenuation-in-urp)
    - [Distance Attenuation](#distance-attenuation)
    - [Spot Angle Attenuation](#spot-angle-attenuation)
    - [Reference](#reference)
  - [关于聚光灯光源一点小误解](#关于聚光灯光源一点小误解)

## 说明

学习Unity、URP、HDRP的笔记

## 笔记

### ScriptableCullingParameters.conservativeEnclosingSphere

这个[属性](https://docs.unity.cn/2023.2/Documentation/ScriptReference/Rendering.ScriptableCullingParameters-conservativeEnclosingSphere.html)用以控制是否使用一个保守的迭代方案来来计算阴影级联中的每个级联包围球的大小与位置，可以使用[numIterationsEnclosingSphere](https://docs.unity.cn/2023.2/Documentation/ScriptReference/Rendering.ScriptableCullingParameters-numIterationsEnclosingSphere.html)来设置迭代次数，迭代次数默认是64次;

当这个属性设置为`false`时，每个级联包围球的大小会比每个级联视锥体区域小，每个级联包围球和每个级联视锥体区域没有完全重合会导致处于级联视锥体区域角落的但不处于级联包围球内的物体被错误的剔除掉；

当这个属性设置为`true`时，级联包围球会完全包裹住级联视锥区域，此时每个级联包围球的大小会明显变大，这会使阴影贴图覆盖更大的世界空间，当然这也会导致更明显的透视锯齿；

---

### RenderBufferLoadAction

此[枚举](https://docs.unity.cn/ScriptReference/Rendering.RenderBufferLoadAction.html)描述的是在切换渲染目标后，当 GPU 开始渲染到新渲染目标中时，此设置指定应对该表面的现有内容执行的操作。如果在渲染绘制的过程中，切换了渲染目标后，再继续切换回老的渲染目标时，想继续在第一次切换渲染目标前的内容上继续渲染时，就需要使用 `RenderBufferLoadAction.Load` 操作。举个例子，比如先在 RenderTexture A 上绘制了一个球体，然后切换到 RenderTexture B绘制了另外的东西，最后还想继续切换到 RenderTexture A额外绘制新的东西，此时就需要 `RenderBufferLoadAction.Load` 操作。在一些使用 Tile-Based 的 GPU 设备，比如移动端，`Load` 操作会导致 Render Texture A需要从 `local memory` 复制到 `tile memory`，这会造成带宽的增加，从而导致设备发热。所以在这些设备上，要尽量使用 `Clear` 或者 `DontCare` 操作。

在官方文档中还有一个说明：**请注意，并不是所有平台都有加载/存储操作，因此在运行时可能忽略此设置。通常，面向移动端的图形API（OpenGL ES、Metal）会利用这些设置**。当我在写自己的SPR渲染管线时，确实遇到了这个问题，在Windows环境下，此时API使用的是 DirectX 11，切换回老的渲染目标时，指定的操作是 `DontCare`，这时之前绘制的内容还存在并且能正确显示，而在 MacOS 环境下（芯片是移动端架构的 Apple M1 Max），API使用的是 Metal，如果还是使用 `DontCare` 操作，渲染目标会显示错乱，之前绘制的内容也不存在，此时必须使用 `Load` 操作才可以正确的显示出切换渲染目标前绘制的内容。

---

### LUT(Look Up Table) for Color Grading in URP

在URP中，当相机开启了后处理选项以及成功创建 PostProcessPass 时，会创建一个 ColorGradingLutPass 来渲染一张 LUT 图用来做颜色分级(Color Grading)相关的后处理效果，目前包含的后处理效果有：颜色调整(Color Adjustments)，白平衡(White Balance)，拆分着色(Split Toning)，通道混合器(Channel Mixer)，阴影、中间调、高光(Shadows Midtones Highlights)，提升、伽马和增益(Lift, Gamma, and Gain)，颜色曲线(Color Curves)和色调映射(Tonemapping)，需要注意的是，颜色调整中的曝光是单独处理的，并没有包含在 LUT 中。

![09_LUT_with_no_effects](/assets/images/2024/2024-03-13-URPNotes/09_LUT_with_no_effects.png)

![10_LUT_with_ACESTonemapping_and_100ContrastColorAdjustments](/assets/images/2024/2024-03-13-URPNotes/10_LUT_with_ACESTonemapping_and_100ContrastColorAdjustments.png)

上面2个 LUT 图分别为没有应用任何颜色分级效果的 LUT 图和应用了ACES色调映射和100对比度的 LUT 图

有一点需要注意，对于开启和未开启 HDR，渲染和使用 LUT 图有着不同的逻辑，以下要分析的都是开启 HDR 下的情况，没有开启 HDR 的情况最后再分析。

ColorGradingLutPass 会根据 URP Asset 中设置的 LUT size，渲染一张高为 `size`，宽为 `size * size` 的 LUT 纹理，这个 LUT 纹理会应用所有开启的颜色分级效果。先来看看没有应用任何颜色分级效果的 LUT 是怎么渲染出来的，下面是片元着色器的代码：

```c++
float4 FragLutBuilderHdr(Varyings input) : SV_Target
{
    // Lut space
    // We use Alexa LogC (El 1000) to store the LUT as it provides a good enough range
    // (~58.85666) and is good enough to be stored in fp16 without losing precision in the
    // darks
    float3 colorLutSpace = GetLutStripValue(input.texcoord, _Lut_Params);  // 根据 uv 生成出输出颜色

    // Color grade & tonemap
    float3 gradedColor = ColorGrade(colorLutSpace);  // 颜色分级

    // 色调映射
    #ifdef HDR_COLORSPACE_CONVERSION // HDR 输出相关
    gradedColor = ProcessColorForHDR(gradedColor);
    #else
    gradedColor = Tonemap(gradedColor);
    #endif

    return float4(gradedColor, 1.0);
}
```

可以看到首先是根据 uv 生成出输出颜色，然后通过 `ColorGrade` 方法应用所有的颜色分级效果，最后做色调映射。继续来看 `GetLutStripValue` 方法是怎么根据 `uv` 生成输出颜色的：

```c++
// Returns the default value for a given position on a 2D strip-format color lookup table
// params = (lut_height, 0.5 / lut_width, 0.5 / lut_height, lut_height / lut_height - 1)
float3 GetLutStripValue(float2 uv, float4 params)
{
    // scale up x from [0,1] to [0,lut_height], so that x is an integer at LUT boundaries (arranged in a strip)
    uv.x *= params.x;

    // make x vary between 0 and 1 within its LUT
    float lutBase = floor(uv.x);
    uv.x -= lutBase;

    // get the LUT index as value between 0 and (lut_height - 1)/lut_height
    float lutBaseU = lutBase * 2.0 * params.z;

    // shift the UV to vary between 0 and (lut_height - 1)/lut_height, arrange as color
    float3 color;
    color.rg = uv - params.zz;
    color.b = lutBaseU;

    // scale to vary between 0 and 1
    return color * params.w;
}
```

其中，`_Lut_Params` 参数的数据是 `(lut_height, 0.5 / lut_width, 0.5 / lut_height, lut_height / lut_height - 1)`。

首先把 `uv.x` 分量的从 `[0, 1]` 放大到 `[0, lut_height]`：

```c++
uv.x *= params.x;
```

然后 `uv.x` 分量被分割成了 `lut_height` 个 `[0, 1]`：

```c++
float lutBase = floor(uv.x);
uv.x -= lutBase;
```

下面的 `lutBaseU = lutBase * 2.0 * params.z` 可以变换为：

$$
lutBaseU = lutBase * 2.0 * params.z = lutBase * 2.0 * \frac{0.5}{lut_height} = \frac{lutBase}{lut_height}
$$

而 `lutBase` 是范围为 `[0, lut_height]` 平滑增长的 `uv.x` 分量向下取整，也就是 $0, 1, 2, ... , lut_height - 1$ 这 `lut_height` 个整数，所以上面计算的 `lutBaseU` 就是下面这 `lut_height` 个数：

$$
\frac{0}{lut_height}, \
\frac{1}{lut_height}, \
\frac{2}{lut_height}, \
... \  , \ 
\frac{lut_height - 1}{lut_height}
$$

此时纹理如下图，可以看到在 `x` 分量方向上，被分割成一个个递增加 $\frac{1}{lut_height}$ 的 LUT：

![11_LUT_BaseU](/assets/images/2024/2024-03-13-URPNotes/11_LUT_BaseU.png)

最后，就是分别计算输出颜色的 `R, G, B` 三个通道的值了，最后的代码：

```c++
// shift the UV to vary between 0 and (lut_height - 1)/lut_height, arrange as color
float3 color;
color.rg = uv - params.zz;
color.b = lutBaseU;

// scale to vary between 0 and 1
return color * params.w;
```

  - `R` 通道：

    在 `uv.x` 分量方向，此时 `uv.x` 已经被分割成了 `lut_height` 个 `[0, 1]` 的 Tile，此时先把每个 Tile 的 `x` 分量转换到 $[0, \frac{lut_height - 1}{lut_height}]$，最后再乘以 $\frac{lut_height}{lut_height - 1}$，最终转换到 `[0, 1]`；

    ![12_LUT_R_Channel](/assets/images/2024/2024-03-13-URPNotes/12_LUT_R_Channel.png)

  - `G` 通道：

    在 `uv.y` 分量方向，和 `R` 通道处理一样，也是先转换到 $[0, \frac{lut_height - 1}{lut_height}]$，最后再乘以 $\frac{lut_height}{lut_height - 1}$，最终转换到 `[0, 1]`；

    ![13_LUT_G_Channel](/assets/images/2024/2024-03-13-URPNotes/13_LUT_G_Channel.png)

  - `B` 通道：

    `B` 通道记录的就是 `lutBaseU`，也就是 $\frac{0}{lut_height}, \frac{1}{lut_height}, \frac{2}{lut_height}, \ ... \  , \ \frac{lut_height - 1}{lut_height}$ 这 `lut_height` 个值：

    ![14_LUT_B_Channel](/assets/images/2024/2024-03-13-URPNotes/14_LUT_B_Channel.png)

现在得到了通过 `uv` 坐标生成出的 LogC 空间的颜色，后续就是转换到不同的颜色空间然后应用各种颜色分级效果，最后输出到渲染目标纹理。这样就得到了一个应用了所需颜色分级效果的一个颜色 LUT 图，在最终的 Uber Pass 中，通过输入的颜色值，就可以通过查找颜色 LUT 图的形式快速的得到应用所有颜色分级效果后的颜色值，
不需要对渲染目标上的每个像素应用所有的颜色分级计算，大大的提高了性能。

现在来看看在 Uber Pass 中是怎么使用这样 LUT 图的，在 `UberPost.shader` 中的 `ApplyColorGrading` 方法，先把颜色值从线性空间转换到 LogC 空间，然后调用 `ApplyLut2D` 方法：

```c++
float3 inputLutSpace = saturate(LinearToLogC(input)); // LUT space is in LogC
input = ApplyLut2D(TEXTURE2D_ARGS(lutTex, lutSampler), inputLutSpace, lutParams);
```

```c++
// 2D LUT grading
// scaleOffset = (1 / lut_width, 1 / lut_height, lut_height - 1)
float3 ApplyLut2D(TEXTURE2D_PARAM(tex, samplerTex), float3 uvw, float3 scaleOffset)
{
    // Strip format where `height = sqrt(width)`
    uvw.z *= scaleOffset.z;
    float shift = floor(uvw.z);
    uvw.xy = uvw.xy * scaleOffset.z * scaleOffset.xy + scaleOffset.xy * 0.5;
    uvw.x += shift * scaleOffset.y;
    uvw.xyz = lerp(
        SAMPLE_TEXTURE2D_LOD(tex, samplerTex, uvw.xy, 0.0).rgb,
        SAMPLE_TEXTURE2D_LOD(tex, samplerTex, uvw.xy + float2(scaleOffset.y, 0.0), 0.0).rgb,
        uvw.z - shift
    );
    return uvw;
}
```

在 `ApplyLut2D` 方法中，先把输入颜色的 `B` 通道的值从 `[0, 1]` 放大到 `[0, lut_height - 1]`，然后对 `B` 通道的值向下取整，得到每个 Tile 的值 `shift`，也就是 `lut_height` 个数，分别是 $0, 1, 2, ..., lut_height - 1$,
而 `R` 通道从 `[0, 1]` 转换到 $[\frac{0.5}{lut_width}, \frac{lut_height - 0.5}{lut_width}]$，然后再加上 `shift * scaleOffset.y`，还因为 `lut_width = lut_height * lut_height`，所以得到 `R` 通道的范围是：

$$
[\frac{0.5}{lut_width}, \frac{lut_height - 0.5}{lut_width}] \Rightarrow [\frac{0.5}{(lut_height)^2}, \frac{(lut_height)^2 - 0.5}{(lut_height)^2}]
$$

也就是 LUT 图中在 `uv.x` 分量方向上第一个 Tile 的纹素中心到最后一个 Tile 的纹素中心。最后 `G` 通道就是在 `uv.y` 分量方向的 `[0, 1]` 的平滑过度。

这时输入颜色的 `R` 通道和 `G` 通道转换到为 LUT 图的 `uv` 坐标，那 `B` 通道呢？因为 LUT 图中，`B` 通道存储的是 `lut_height` 个 Tile 的值，此时的做法就是采样当前纹素的值以及相邻的下一个纹素的值，再根据 `uv.x` 的值在这2次值之间做插值计算，就能得到
最终的应用了颜色分级效果的输出颜色了：

```c++
uvw.xyz = lerp(
    SAMPLE_TEXTURE2D_LOD(tex, samplerTex, uvw.xy, 0.0).rgb,
    SAMPLE_TEXTURE2D_LOD(tex, samplerTex, uvw.xy + float2(scaleOffset.y, 0.0), 0.0).rgb,
    uvw.z - shift
);
return uvw;
```

#### 总结

- LUT 图是怎么存储颜色的

  根据 `uv` 坐标，将 LUT 图分割成 `lut_height` 个 Tile，每个 Tile 的尺寸是 `lut_height x lut_height` (比如设置的是32，则有32个 Tiles，每个 Tile 尺寸为32x32)。每个 Tile 的 `R` 通道都是平滑变化的 $0 \rightarrow 1$，每个 Tile 的 `G` 通道也是平滑变化的 $0 \rightarrow 1$，而每个 Tile 的 `B` 通道存储的是一个同样的值，从 0 开始，每个 Tile 的值递增 $\frac{1}{lut_height}$ 的 `lut_height` 个值。
  所以，LUT 图可以存储 `lut_height x lut_height x lut_height` 种颜色(一张 `1024 * 32` 的 LUT 图可以存储 `32 x 32 x 32 = 32768` 种颜色)，虽然一张 LUT 图能存储的颜色数量是有上限的，但是在使用的过程中，通过双线性插值采样器 `sampler_LinearClamp` 可以在存储的颜色之间做插值得到平滑过度的更多的其它颜色。

- LUT 图是怎么使用的

  首先根据输入颜色的 `B` 通道确定此输入颜色处于 LUT 图中的哪一个 Tile，然后通过 `R` 通道和 `G` 通道得到采样 LUT 的 `uv` 坐标，最后采样当前 Tile 和相邻 Tile 的颜色值，通过输入 `R` 通道的值计算得到2个 Tile 之间的距离，根据距离在这2次采样 Tile 的颜色值之间做插值即可得到最终的输出颜色。

#### 是否开启HDR渲染的差别

- LUT 的纹理格式不同，开启 HDR 时，是 `GraphicsFormat.R16G16B16A16_SFloat`，未开启 HDR 时，是 `GraphicsFormat.R8G8B8A8_UNorm`;
- LUT 渲染的颜色空间不同，开启 HDR 时，颜色存储在 LogC 空间，相比线性空间它有更好的颜色范围(~58.85666)，并且可以为极小的值提供更好的精度，而未开启 HDR 时，颜色存储在线性空间 0-1;
- 开启 HDR 时，色调映射效果会应用到 LUT 图中，未开启 HDR 时，色调映射是在 Uber Pass 中计算的；

---

### Distance Attenuation and Spot Angle Attenuation in URP

#### Distance Attenuation

在URP中，点光源和聚光灯强度的距离衰减满足平方反比定律([the inverse-square law](https://en.wikipedia.org/wiki/Inverse-square_law))，即光源的强度会按照距离光源的距离的平方反比而下降，也就是：

$$
\mathbf{attenuation} = \frac{1.0}{\mathbf{distanceSqr}};
$$

其中 $\mathbf{distanceSqr}$ 表示与光源之间的距离的平方。而Unity还引入了一个叫做平滑因子(Smooth Factor)的变量，用来保证在光源边界时光源的强度为0，平滑因子的计算公式是：

$$
\mathbf{smoothFactor} = (saturate(1.0 - (\mathbf{distanceSqr} * \mathbf{1.0 / lightRangeSqr})^2))^2;
$$

其中 `lightRangeSqr` 是光源范围的平方，`distanceSqr` 是与光源之间的距离的平方，最终距离的衰减就是：

$$
\mathbf{distanceAttenuation} = \mathbf{attenuation} * \mathbf{smoothFactor};
$$

在URP的源码中，先在CPU中计算 `1.0 / lightRangeSqr`，并通过 `_AdditionalLightsAttenuation` 的 `x` 分量传入到GPU中：

```C#
internal static void GetPunctualLightDistanceAttenuation(float lightRange, ref Vector4 lightAttenuation)
{
    // Light attenuation in universal matches the unity vanilla one (HINT_NICE_QUALITY).
    // attenuation = 1.0 / distanceToLightSqr
    // The smoothing factor makes sure that the light intensity is zero at the light range limit.
    // (We used to offer two different smoothing factors.)

    // The current smoothing factor matches the one used in the Unity lightmapper.
    // smoothFactor = (1.0 - saturate((distanceSqr * 1.0 / lightRangeSqr)^2))^2
    float lightRangeSqr = lightRange * lightRange;
    float fadeStartDistanceSqr = 0.8f * 0.8f * lightRangeSqr;
    float fadeRangeSqr = (fadeStartDistanceSqr - lightRangeSqr);
    float lightRangeSqrOverFadeRangeSqr = -lightRangeSqr / fadeRangeSqr;
    float oneOverLightRangeSqr = 1.0f / Mathf.Max(0.0001f, lightRangeSqr);

    // On all devices: Use the smoothing factor that matches the GI.
    lightAttenuation.x = oneOverLightRangeSqr;
    lightAttenuation.y = lightRangeSqrOverFadeRangeSqr;
}
```

在y分量计算存储了另外一种算法的平滑因子，暂时没有使用。在最终的Shader计算中，会去计算剩余的部分：

```c++
// Matches Unity Vanilla HINT_NICE_QUALITY attenuation
// Attenuation smoothly decreases to light range.
float DistanceAttenuation(float distanceSqr, half2 distanceAttenuation)
{
    // We use a shared distance attenuation for additional directional and puctual lights
    // for directional lights attenuation will be 1
    float lightAtten = rcp(distanceSqr);
    float2 distanceAttenuationFloat = float2(distanceAttenuation);

    // Use the smoothing factor also used in the Unity lightmapper.
    half factor = half(distanceSqr * distanceAttenuationFloat.x);
    half smoothFactor = saturate(half(1.0) - factor * factor);
    smoothFactor = smoothFactor * smoothFactor;

    return lightAtten * smoothFactor;
}
```

#### Spot Angle Attenuation

聚光灯有一个角度用来控制其光锥的宽度，叫做Outer Spot Angle，还有一个角度用来控制光源强度在角度上什么时候开始衰减。

![05_spotlight_inner_outer_angle](/assets/images/2024/2024-03-13-URPNotes/05_spotlight_inner_outer_angle.png)

上图就是描述了一个聚光灯的定义，绿色的角度是Outer Spot Angle，红色的角度 $\theta$ 是Inner Spot Angle。下面展示了在Unity中，同样是 $90\degree$ 的Outer Spot Angle下， $20\degree$ 和 $90\degree$ 的Inner Spot Angle分别的表现，可以看到Inner Spot Angle控制的是聚光灯由内到外的一个强度衰减：

![06_different_inner_spot_angle](/assets/images/2024/2024-03-13-URPNotes/06_different_inner_spot_angle.png)

在URP中，聚光灯角度的衰减可以表示为：

$$
\mathbf{spotAttenuation} = saturate((\mathbf{SdotL} - \mathbf{cosOuterAngle}) / (\mathbf{cosInnerAngle} - \mathbf{cosOuterAngle}))
$$

其中 `SdotL` 表示的是光线方向向量和聚光灯方向向量的点乘，`cosOuterAngle` 是Outer Spot Angle的余弦值，`cosInnerAngle` 是Inner Spot Angle的余弦值。

首先来看看余弦函数：

![07_graph_of_cosine](/assets/images/2024/2024-03-13-URPNotes/07_graph_of_cosine.png)

可以看到角度越小，余弦函数的值越大，而向量的点乘可以理解为就是求两个向量夹角的余弦值，最终角度衰减的线性变化就是实际光线方向和聚光灯方向的夹角的余弦值与总的衰减范围角度的余弦值的比。

![08_spot_light](/assets/images/2024/2024-03-13-URPNotes/08_spot_light.png)

当实际光线方向在Inner Spot Angle内时，此时 `SdotL - cosOuterAngle` 大于 `cosInnerAngle - cosOuterAngle`，最终 `spotAttenuation` 被限制在强度1.0，当实际光线方向超出Inner Spot Angle开始向Outer Spot Angle偏移时，此时 `SdotL - cosOuterAngle` 开始小于 `cosInnerAngle - cosOuterAngle`，也就代表开始衰减，最终接近Outer Spot Angle时，强度衰减接近0.0。

在URP源码中，Unity将公式分解成乘项和加项，分别通过 `_AdditionalLightsAttenuation` 的 `z、w` 分量传入到GPU：

$$
\mathbf{invAngleRange = 1.0 / (cosInnerAngle - cosOuterAngle)};\\
\mathbf{addTerm = (-cosOuterAngle * invAngleRange)};\\
\mathbf{spotAttenuation = SdotL * invAngleRange + addTerm};
$$

```csharp
internal static void GetSpotAngleAttenuation(float spotAngle, float? innerSpotAngle,ref Vector4 lightAttenuation)
{
    // Spot Attenuation with a linear falloff can be defined as
    // (SdotL - cosOuterAngle) / (cosInnerAngle - cosOuterAngle)
    // This can be rewritten as
    // invAngleRange = 1.0 / (cosInnerAngle - cosOuterAngle)
    // SdotL * invAngleRange + (-cosOuterAngle * invAngleRange)
    // If we precompute the terms in a MAD instruction
    float cosOuterAngle = Mathf.Cos(Mathf.Deg2Rad * spotAngle * 0.5f);
    // We need to do a null check for particle lights
    // This should be changed in the future
    // Particle lights will use an inline function
    float cosInnerAngle;
    if (innerSpotAngle.HasValue)
        cosInnerAngle = Mathf.Cos(innerSpotAngle.Value * Mathf.Deg2Rad * 0.5f);
    else
        cosInnerAngle = Mathf.Cos((2.0f * Mathf.Atan(Mathf.Tan(spotAngle * 0.5f * Mathf.Deg2Rad) * (64.0f - 18.0f) / 64.0f)) * 0.5f);
    float smoothAngleRange = Mathf.Max(0.001f, cosInnerAngle - cosOuterAngle);
    float invAngleRange = 1.0f / smoothAngleRange;
    float add = -cosOuterAngle * invAngleRange;

    lightAttenuation.z = invAngleRange;
    lightAttenuation.w = add;
}
```

而聚光灯方向通过 `_AdditionalLightsSpotDir` 传入到 GPU 中：

```csharp
internal static void GetSpotDirection(ref Matrix4x4 lightLocalToWorldMatrix, out Vector4 lightSpotDir)
{
    Vector4 dir = lightLocalToWorldMatrix.GetColumn(2);
    lightSpotDir = new Vector4(-dir.x, -dir.y, -dir.z, 0.0f);
}
```

最终在 Shader 中，只需要计算实际的光线方向和聚光灯方向的点乘，然后再通过在 CPU 计算好的乘项和加项计算出最终的角度衰减：

```c++
half AngleAttenuation(half3 spotDirection, half3 lightDirection, half2 spotAttenuation)
{
    // Spot Attenuation with a linear falloff can be defined as
    // (SdotL - cosOuterAngle) / (cosInnerAngle - cosOuterAngle)
    // This can be rewritten as
    // invAngleRange = 1.0 / (cosInnerAngle - cosOuterAngle)
    // SdotL * invAngleRange + (-cosOuterAngle * invAngleRange)
    // SdotL * spotAttenuation.x + spotAttenuation.y

    // If we precompute the terms in a MAD instruction
    half SdotL = dot(spotDirection, lightDirection);
    half atten = saturate(SdotL * spotAttenuation.x + spotAttenuation.y);
    return atten * atten;
}
```

#### Reference

- [Light casters](https://learnopengl.com/Lighting/Light-casters)
- [Types of Light](https://docs.unity3d.com/2023.2/Documentation/Manual/Lighting.html)
- [Point and Spot Lights](https://catlikecoding.com/unity/tutorials/custom-srp/point-and-spot-lights/)

---

### 关于聚光灯光源一点小误解

一直以为聚光灯是这样的：

![00_wrong_spotlight](/assets/images/2024/2024-03-13-URPNotes/00_wrong_spotlight.png)

大错特错！！！其实它是这样的：

![01_correct_spotlight](/assets/images/2024/2024-03-13-URPNotes/01_correct_spotlight.png)

<!-- --- -->

<!-- ### VisibleLight.localToWorldMatrix 矩阵的第3列和第4列的意义 -->

<!-- TODO -->
<!-- // For directional light, lightPos is a direction, and in light's local space, it's forward direction in local space is (0,0,1),
// after is multiplied by light's localToWorld matrix:
// localToWorldMatrix * (0,0,1,0), a direction has 0 in homogeneous coordinate;
// it returns the column 2 of the light's localToWorld matrix, and in lighting calculation in Shader,
// the light directional vector needs to point to light, so negative the direction here

// For point light and spot light, lightPos is a position in world space, it's original position in local space is (0,0,0),
// after is multiplied by light's localToWorld matrix:
// localToWorldMatrix * (0,0,0,1), a position has 1 in homogeneous coordinate;
// it returns the column 3 of the light's localToWorld matrix

// For spot light's direction, and in light's local space, it's forward direction in local space is (0,0,1),
// after is multiplied by light's localToWorld matrix:
// localToWorldMatrix * (0,0,1,0), a direction has 0 in homogeneous coordinate;
// it returns the column 2 of the light's localToWorld matrix, and in lighting calculation in Shader,
// the spot directional vector needs to point to light, so negative the direction here -->

<!-- ---

### RenderTexture.memorylessMode

<!-- TODO -->
<!-- https://discussions.unity.com/t/rendertexture-memorylessmode/661299 -->
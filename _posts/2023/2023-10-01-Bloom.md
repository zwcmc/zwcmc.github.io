---
layout: post
title:  "泛光（Bloom）"
date:   2023-10-01 16:16:00 +800
category: Rendering
---

- [(1) 什么是泛光](#1-什么是泛光)
- [(2) 泛光的原理](#2-泛光的原理)
  - [2.1 阈值处理](#21-阈值处理)
  - [2.2 模糊](#22-模糊)
  - [2.3 应用泛光](#23-应用泛光)
- [(3) 高动态范围（HDR）与泛光](#3-高动态范围hdr与泛光)
- [(4) 快速的大范围模糊](#4-快速的大范围模糊)
  - [4.1 通过创建 Mipmap 链（Mipmap Chain）来快速做大范围的模糊](#41-通过创建-mipmap-链mipmap-chain来快速做大范围的模糊)
- [(5) 应用大范围的模糊](#5-应用大范围的模糊)
  - [5.1 解决闪烁的问题（Fireflies）](#51-解决闪烁的问题fireflies)
- [(6) 总结](#6-总结)
- [(7) 参考](#7-参考)

## (1) 什么是泛光

泛光（Bloom）是实时渲染中的一种后期处理技术，用以模拟现实世界中相机镜头或人眼在观察明亮光源时产生的一种光晕现象，这种现象被称作 **眩光（Glare）** 。

![00_bloom](/assets/images/2023/2023-10-01-Bloom/00_bloom.jpeg)

## (2) 泛光的原理

泛光的原理可以通过下面一张图来很好的解释：

![01_implement_bloom](/assets/images/2023/2023-10-01-Bloom/01_implement_bloom.jpg)

1. 通过使用一个阈值（Threshold）提取图像中高亮的像素
2. 对提取出来的高亮像素做模糊（Blur）
3. 将模糊后的图像应用到原图像上

### 2.1 阈值处理

阈值处理的目的是仅保留图像中非常明亮的像素来增强光晕效果。虽然通过这种方法可以让画面中明亮的区域更加突出，但是它并不是物理正确的（在现实世界中，不存在阈值处理，每一个物体都有泛光的效果，只不过亮度低的物体的泛光效果非常非常微弱）。

没有阈值处理的优势是结果更加真实自然，它会使图像有一种柔和感。最终需不需要做阈值处理取决于艺术风格的方向。

### 2.2 模糊

我们知道，模糊的本质是对原图像进行 **低通滤波（Low Pass Filter）** ：对于图像中的每个像素，将被滤波器覆盖的该像素及其周围的像素，进行加权平均，并将结果作为新的像素值。通过模糊操作，可以很好的将高亮的像素向周围像素扩散，以模拟光晕的现象。

### 2.3 应用泛光

通过模糊得到泛光图像后，通常的做法是通过简单的加法将泛光图像叠加到原图像上。但是对于没有使用阈值处理的泛光图像，使用线性插值混合原图像与泛光图像可能是更好的一个方案。

## (3) 高动态范围（HDR）与泛光

高动态范围纹理允许像素的亮度值超过 255 ，这能够很好的描述真实世界中的亮度。而且在泛光中，更高的亮度值意味着这个像素可以扩散的更远。

下面是一组对比图，对不同亮度的像素应用相同的大范围模糊处理，可以看到， 1.0 像素亮度在模糊后，被分摊到很小的值（肉眼难以分辨），而 10.0 像素亮度在模糊后，即使处于模糊边缘也能够累积客观的亮度。也就是说， **像素越亮，它通过模糊扩散的距离就越远** ：

![03_hdr_bloom_00](/assets/images/2023/2023-10-01-Bloom/03_hdr_bloom_00.jpeg)
![03_hdr_bloom_01](/assets/images/2023/2023-10-01-Bloom/03_hdr_bloom_01.jpeg)
![03_hdr_bloom_02](/assets/images/2023/2023-10-01-Bloom/03_hdr_bloom_02.jpeg)

## (4) 快速的大范围模糊

想要光晕扩散的足够大，首先想到的就是扩大模糊的范围，一种非常简单的思路就是使用一个巨大的滤波器对图像进行模糊。然而，这种方法的问题在于它很快会对性能产生极大的负担。例如，对于一个使用高斯方程生成出的 $N \times N$ 的滤波器的模糊来说，图像中每个像素的采样次数将会是 $N^2$ 次！虽然利用高斯方程可拆分的特性，可以通过两次模糊（先水平模糊再垂直模糊）将每个像素采样次数降低为 $N + N$ ，但是对于想要大范围的模糊来说，这种性能消耗还是太高了。

我们知道，模糊的本质可以总结为：查找滤波器覆盖范围的每个像素的亮度值，对这些值进行加权平均。当说到一定范围内的像素值，不得不提到 Mipmap ：每一层级 Mipmap 都是上一层级 Mipmap 一半的大小（分辨率），对于 `Level 2` 的 Mipmap 中的一个像素值，代表了 `Level 1` 的 Mipmap 中的 $2 \times 2$ 像素块均值，也代表了 `Level 0` 的 Mipmap 中的 $4 \times 4$ 像素块均值。 **也就是说，通过使用 Mipmap ，可以快速的做大范围的模糊** 。

### 4.1 通过创建 Mipmap 链（Mipmap Chain）来快速做大范围的模糊

利用 Mipmap 的原理，我们可以创建一个 Mipmap 链：对原图像（Mipmap Level = 0）进行多次 **降采样（Downsampling）** ，每次降采样都将图像 Blit 到一半尺寸的下一层级 Mipmap 上，并且利用 **双线性过滤（Bilinear Filtering）** 只需采样 1 次上一层级 Mipmap ，就可以得到上一层级 Mipmap 中 $2 \times 2$ 像素块的均值。对于 Mipmap 链上 Mipmap Level = 5 的图像中的一个像素的值代表的就是原图像（Mipmap Level = 0）中 $32 \times 32$ 像素块的均值！并且，双线性过滤是硬件 GPU 支持的算法，它的计算是非常快的，对性能的消耗几乎可以忽略不计。

下面有一个简单的两次降采样的示意图：

![04_downsampling](/assets/images/2023/2023-10-01-Bloom/04_downsampling.jpeg)

可以看到，原图像的分辨率是 $4 \times 4$ ，第 1 次降采样后，原图像被 Blit 到一个 $2 \times 2$ 的图像中，降采样后的图像中红色的像素 $F$ 对应的原图像的红色的采样点 $E$ 的位置，采样点的位置在周围蓝色 4 个像素 $A,B,C,D$ 的正中间，而双线性过滤的算法我们知道，可以表示为：

$$
\begin{align*}
E0 &= (1.0 - 0.5) * A + 0.5 * B \\
E1 &= (1.0 - 0.5) * C + 0.5 * D \\
E &= (1.0 - 0.5) * E0 + 0.5 * E1 \\
&= 0.25 * (A + B + C + D)
\end{align*}
$$

也就是说降采样后的图像中的一个像素值等于上一层级图像中 $2 \times 2$ 像素块的均值。那么第二次降采样后呢，此时一个像素的值等于原图像中 $4 \times 4$ 像素块的均值。

在足够高的 Mipmap 层级下，模糊的范围确实增大了，但是模糊的效果不够好，这是因为双线性过滤的本质是一个 $2 \times 2$ 的滤波器，仅仅使用这么小的一个滤波器进行下采样会产生块状的结果：

![05_downsampling_bilinear](/assets/images/2023/2023-10-01-Bloom/05_downsampling_bilinear.jpg)

**通过在降采样的过程中进行额外的模糊操作可以使模糊的效果更佳平滑** 。降采样中额外的模糊算法有很多，我们就不一一说明了，下面就说说 UE4 和 COD 的做法。

在 UE4 中，将简单 1 次双线性过滤采样扩展为 4 次，也就是下图中蓝色的采样点到红色的采样点，通过 4 次双线性过滤采样并平均采样的结果，得到上一层级图像中 $4 \times 4$ 像素块的均值：

![06_downsampling_ue4](/assets/images/2023/2023-10-01-Bloom/06_downsampling_ue4.jpg)

实现的代码也很简单：

```glsl
vec3 box4x4(vec3 s0, vec3 s1, vec3 s2, vec3 s3) {
    return (s0 + s1 + s2 + s3) * 0.25;
}

vec3 c0  = textureLodOffset(uSourceTex, uv, 0.0, ivec2(-1, -1)).rgb;
vec3 c1  = textureLodOffset(uSourceTex, uv, 0.0, ivec2( 1, -1)).rgb;
vec3 c2  = textureLodOffset(uSourceTex, uv, 0.0, ivec2( 1,  1)).rgb;
vec3 c3  = textureLodOffset(uSourceTex, uv, 0.0, ivec2(-1,  1)).rgb;
vec3 color = box4x4(c0, c1, c2, c3);
```

通过这种方法得到的结果好了不少：

![07_downsampling_ue4_b](/assets/images/2023/2023-10-01-Bloom/07_downsampling_ue4_b.jpg)

在 COD 中，他们在 UE4 方法的基础上，扩展到了 13 次双线性过滤采样：

![08_downsampling_cod](/assets/images/2023/2023-10-01-Bloom/08_downsampling_cod.jpg)

代码如下：

```glsl
// see SIGGRAPH 2014: Advances in Real-Time Rendering
//     "Next Generation Post-Processing in Call of Duty Advanced Warfare"
//      Jorge Jimenez
vec3 c = textureLod(uSourceTex, uv, 0.0).rgb;

// The offsets below are in "source" texture space
vec3 lt  = textureLodOffset(uSourceTex, uv, 0.0, ivec2(-1, -1)).rgb;
vec3 rt  = textureLodOffset(uSourceTex, uv, 0.0, ivec2( 1, -1)).rgb;
vec3 rb  = textureLodOffset(uSourceTex, uv, 0.0, ivec2( 1,  1)).rgb;
vec3 lb  = textureLodOffset(uSourceTex, uv, 0.0, ivec2(-1,  1)).rgb;

vec3 lt2 = textureLodOffset(uSourceTex, uv, 0.0, ivec2(-2, -2)).rgb;
vec3 rt2 = textureLodOffset(uSourceTex, uv, 0.0, ivec2( 2, -2)).rgb;
vec3 rb2 = textureLodOffset(uSourceTex, uv, 0.0, ivec2( 2,  2)).rgb;
vec3 lb2 = textureLodOffset(uSourceTex, uv, 0.0, ivec2(-2,  2)).rgb;

vec3 l   = textureLodOffset(uSourceTex, uv, 0.0, ivec2(-2,  0)).rgb;
vec3 t   = textureLodOffset(uSourceTex, uv, 0.0, ivec2( 0, -2)).rgb;
vec3 r   = textureLodOffset(uSourceTex, uv, 0.0, ivec2( 2,  0)).rgb;
vec3 b   = textureLodOffset(uSourceTex, uv, 0.0, ivec2( 0,  2)).rgb;

// five h4x4 boxes
vec3 c0, c1;

// common case
c0  = box4x4(lt, rt, rb, lb);
c1  = box4x4(c, l, t, lt2);
c1 += box4x4(c, r, t, rt2);
c1 += box4x4(c, r, b, rb2);
c1 += box4x4(c, l, b, lb2);

// weighted average of the five boxes
vec3 color = c0 * 0.5 + c1 * 0.125;
```

模糊后的结果如下：

![09_downsampling_cod_c](/assets/images/2023/2023-10-01-Bloom/09_downsampling_cod_c.jpg)

可以看到模糊的效果比 UE4 的结果要好，模糊的范围更大更自然，当然，性能消耗也更高。

## (5) 应用大范围的模糊

我们通过 Mipmap 链下采样生成了大范围的模糊，现在要解决的，就是怎么将大范围的模糊叠加到原图像上。

直接将 Mipmap 链中最高层级的 Mipmap 叠加到原图像上虽然能够产生足够大的光晕扩散，但是高亮度像素与泛光之间没有过度，亮度上突然的跳变使得泛光的效果非常不自然：

![10_upsampling_highlevel_add](/assets/images/2023/2023-10-01-Bloom/10_upsampling_highlevel_add.jpg)

不管使用何种滤波器，本质上都是在做加权平均，每次模糊都会降低高亮像素的亮度，并将这些亮度分摊到周围的像素，边缘的跳变是因为最高层级 Mipmap 与原图像之间亮度差距过大！下面展示了不同 Mipmap 层级的亮度分布：

![11_mipmap_level0](/assets/images/2023/2023-10-01-Bloom/11_mipmap_level0.jpg)
![11_mipmap_level6](/assets/images/2023/2023-10-01-Bloom/11_mipmap_level6.jpg)
![11_mipmap_level8](/assets/images/2023/2023-10-01-Bloom/11_mipmap_level8.jpg)

为了实现泛光效果的平滑过渡，我们需要叠加所有的 Mipmap 层级到原图上，因为每一层级的 Mipmap 都是基于上一层级的 Mipmap 计算的，通过叠加所有的 Mipmap 层级可以得到一个相对平滑连续的结果：

![12_combine_mipmap_result](/assets/images/2023/2023-10-01-Bloom/12_combine_mipmap_result.jpg)

仔细看上面的结果，虽然泛光已经有了过渡，但是泛光中还是有很多块状瑕疵，因为高等级的 Mipmap 分辨率非常小，利用双线性过滤直接上采样到原图就会出现这种问题，和上面说的下采样类似的原因，双线性过滤只是一个 $2 \times 2$ 的小滤波器。解决的方法也是一样的，通过增加额外的模糊滤波来消除这种块状瑕疵。

直接对每一级 Mipmap 做模糊过滤也是不可行的，对于高等级的 Mipmap 分辨率非常小，甚至小到 $1 \times 1$ ，对其做模糊滤波是效果不大。而对于低等级的 Mipmap 分辨率又非常大，要想有好的模糊效果必须使用很大的滤波器对其进行模糊，这种对性能的消耗又太高。

那么，我们可以利用下采样创建 Mipmap 链的思想，对其进行逆向依次 **上采样（Upsampling）** 。也就是说，对于下采样创建的 Mipmap 链，我们从最高层级的 Mipmap 开始，依次对其做模糊并上采样到上一层级的 Mipmap 并将它们叠加起来。下图展示了 COD 的上采样方案：

![14_upsampling](/assets/images/2023/2023-10-01-Bloom/14_upsampling.jpg)

它们使用了一个 $3 \times 3$ 的滤波器：

![15_upsampling_filter](/assets/images/2023/2023-10-01-Bloom/15_upsampling_filter.jpg)

可以看到通过这种上采样与模糊结合的方式，块状瑕疵的问题被解决了。最终的泛光效果：

![16_upsampling_result](/assets/images/2023/2023-10-01-Bloom/16_upsampling_result.jpg)

### 5.1 解决闪烁的问题（Fireflies）

在 PBR 渲染中，当粗糙度非常小， NdotL 接近 1.0 时，会输出极大的值，尤其是当光源的强度足够高时，高光部分会非常亮。当应用泛光效果时，会造成画面闪烁的问题。

COD 的方案是在第一次下采样时，也就是 Mip0 到 Mip1 时，加入额外的权重来降低这个像素的亮度：

![17_fire_flies](/assets/images/2023/2023-10-01-Bloom/17_fire_flies.jpg)

## (6) 总结

总结一下泛光的实现细节：

- 提取画面中高亮的像素
- 通过 **逐级下采样** 的方式来快速大范围的模糊高亮的像素，并在每次下采样中加入模糊滤波避免双线性过滤造成的块状瑕疵的问题
- 再通过 **逐级上采样** 的方式来叠加每一层级的 Mipmap ，并且每次上采样时也加入模糊滤波使最终的结果过渡更平滑
- 最终将生成出的泛光结果叠加到原图像上

## (7) 参考

- [1] [Bloom (shader effect)](https://en.wikipedia.org/wiki/Bloom_(shader_effect))
- [2] [Physically Based Bloom](https://learnopengl.com/Guest-Articles/2022/Phys.-Based-Bloom)
- [3] [Custom Bloom Post-Process in Unreal Engine](https://www.froyok.fr/blog/2021-12-ue4-custom-bloom/#B13)
- [4] [How to do good bloom for HDR rendering](https://web.archive.org/web/20060818101028/http://harkal.sylphis3d.com/2006/05/20/how-to-do-good-bloom-for-hdr-rendering/)
- [5] [高质量泛光（bloom）从理论到实战](https://zhuanlan.zhihu.com/p/525500877)
- [6] [NEXT GENERATION POST PROCESSING IN CALL OF DUTY: ADVANCED WARFARE](https://www.iryoku.com/next-generation-post-processing-in-call-of-duty-advanced-warfare/)
